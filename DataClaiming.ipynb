{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>Data Claiming</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include libraries\n",
    "from requests_html import HTMLSession\n",
    "import urllib.robotparser\n",
    "import re\n",
    "import requests\n",
    "import requests_cache\n",
    "import time, json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# target link\n",
    "anchor_user = \"one direction\"\n",
    "target_web_link = 'https://soundcloud.com'\n",
    "test_cache_web_link1 = 'https://raw.githubusercontent.com/KienTrann/requests-cache-testing/main/should_be_cached.txt'\n",
    "test_cache_web_link2 = 'https://raw.githubusercontent.com/KienTrann/requests-cache-testing/main/should_not_be_cached.txt'\n",
    "chrome_driver_binary = \"D:\\Sequence\\Comp-Suppoter\\Chrome\\chromedriver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dont care about these lines, I just review the lesson of Lab01\n",
    "(move to Hand on Crawling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag's HTML string: <a class=\"menu-a\" href=\"#\">About</a>\n",
      "Tag's text string: About\n",
      "Attributes dictionary tag: {'class': ('menu-a',), 'href': '#'}\n"
     ]
    }
   ],
   "source": [
    "# get the website source\n",
    "session = HTMLSession()\n",
    "source = session.get('https://thinhsuy.github.io/VisualPage/#')\n",
    "tag = source.html.find('.menu-a', first=True)\n",
    "print(f\"Tag's HTML string: {tag.html}\")\n",
    "print(f\"Tag's text string: {tag.text}\")\n",
    "print(f\"Attributes dictionary tag: {tag.attrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the robot.txt of website\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url(target_web_link+'/robots.txt')\n",
    "rp.read()\n",
    "rp.can_fetch('*', target_web_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['About']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular Expression\n",
    "re.findall(r'\\w{5}', tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running .render() in Jupyter! Run it in powershell file.py instead\n"
     ]
    }
   ],
   "source": [
    "# Working with dynamic webpage\n",
    "session = HTMLSession()\n",
    "source = session.get(target_web_link)\n",
    "try: source.html.render()\n",
    "except: print('Not running .render() in Jupyter! Run it in powershell file.py instead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hand on crawling data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test from link 1: \n",
      "abc\n",
      "xyz\n",
      "\"incomplete_results\":false\n",
      "\n",
      "Test from link 2: \n",
      "abc\n",
      "xyz\n",
      "\"incomplete_results\":true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limit the total step that the request would crawl down data\n",
    "def check_filter(response: requests.models.Response)->bool:\n",
    "    return True if '\"incomplete_result\":true' in response.text else False\n",
    "\n",
    "requests_cache.install_cache(\"my_cache\", filter_fn=check_filter)\n",
    "\n",
    "# Request function\n",
    "sleep_time = 1\n",
    "def get_request(url):\n",
    "    r = requests.get(url)\n",
    "    while not(r.ok):\n",
    "        time.sleep(sleep_time)\n",
    "        r = requests.get(url)\n",
    "    return r\n",
    "\n",
    "# Testing\n",
    "print(f\"Test from link 1: \\n{get_request(test_cache_web_link1).text}\")\n",
    "print(f\"Test from link 2: \\n{get_request(test_cache_web_link2).text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenWebBrowser(driver, link, by=By.ID, id_coockie_trust=\"none\", delay_element_loading=10):\n",
    "    time.sleep(sleep_time)\n",
    "    driver.get(link)\n",
    "    if id_coockie_trust==\"none\": return True\n",
    "    try:\n",
    "        WebDriverWait(driver, delay_element_loading).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (by, id_coockie_trust)\n",
    "            ))\n",
    "    except TimeoutException: \n",
    "        print(\"Runtime out\")\n",
    "        return False\n",
    "    time.sleep(sleep_time)\n",
    "    driver.find_element(by, id_coockie_trust).click()\n",
    "    return True\n",
    "\n",
    "def ScrollScreen(driver, epochs=1, time_sleep=0.5):\n",
    "    for _ in range(epochs):\n",
    "        time.sleep(time_sleep)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "def getElements(driver, by, id, sleep_time=1):\n",
    "    time.sleep(sleep_time)\n",
    "    element = driver.find_elements(by, id)\n",
    "    time.sleep(sleep_time*2)\n",
    "    return element\n",
    "\n",
    "def getRequest(driver, url, sleep_time=1):\n",
    "    driver.get(url)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "def WaitUntilPresense(driver, by, id, delay=5):\n",
    "    try:\n",
    "        WebDriverWait(driver, delay).until(EC.presence_of_element_located((by, id)))\n",
    "        return True\n",
    "    except TimeoutException: \n",
    "        print(\"Runtime out\")\n",
    "        return False\n",
    "\n",
    "def addValue(dictionary, key, value, default='NaN'):\n",
    "    try: dictionary[key] = value\n",
    "    except: dictionary[key] = default\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_user_infor(driver, user_dict):\n",
    "    stats_value = getElements(driver, By.CLASS_NAME, \"infoStats__value\")\n",
    "    user_dict = addValue(user_dict, 'Followers', stats_value[0].text)\n",
    "    user_dict = addValue(user_dict, 'Following', stats_value[1].text)\n",
    "    user_dict = addValue(user_dict, 'Tracks', stats_value[2].text)\n",
    "    lasts_value = getElements(driver, By.CLASS_NAME,'sc-visuallyhidden')\n",
    "    user_dict = addValue(user_dict, 'Last_action', lasts_value[0].text)\n",
    "    user_dict = addValue(user_dict, 'Last_track_played', lasts_value[1].text)\n",
    "    return user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Playlist information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_playlist_infor(driver, playlist_dict):\n",
    "    stats = getElements(driver, By.CLASS_NAME, 'sc-link-secondary')\n",
    "    playlist_dict = addValue(playlist_dict, 'Singer', stats[0].text)\n",
    "    playlist_dict = addValue(playlist_dict, 'Likes', str(stats[1].text).split('\\n')[1])\n",
    "    playlist_dict = addValue(playlist_dict, 'Reposts', str(stats[2].text).split('\\n')[1])\n",
    "    last = getElements(driver, By.CLASS_NAME, 'sc-visuallyhidden')\n",
    "    playlist_dict = addValue(playlist_dict, 'Release', last[0].text)\n",
    "    ScrollScreen(driver, epochs=5)\n",
    "    total_track = getElements(driver, By.CSS_SELECTOR, '.trackList__item.sc-border-light-bottom.sc-px-2x')\n",
    "    playlist_dict = addValue(playlist_dict, 'Total_tracks', len(total_track))\n",
    "    return playlist_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Track information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_track_infor(driver, track_dict):\n",
    "    ScrollScreen(driver)\n",
    "    stats = getElements(driver, By.TAG_NAME, 'span')\n",
    "    try:\n",
    "        for i in range(len(stats)):\n",
    "            if stats[i].text == 'View all likes':\n",
    "                track_dict = addValue(track_dict, 'Release', stats[i-7].text)\n",
    "                track_dict = addValue(track_dict, 'Plays', stats[i-2].text)\n",
    "                track_dict = addValue(track_dict, 'Likes', stats[i+1].text)\n",
    "                track_dict = addValue(track_dict, 'Reposts', stats[i+3].text)\n",
    "                break\n",
    "    except: print('Exception tracks occured!')\n",
    "    return track_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Crawling Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_one_row_information(driver, sleep_time=1, iter=0, list_order=list(string.ascii_lowercase)):\n",
    "    playlist_dict, track_dict, user_dict = dict(), dict(), dict()\n",
    "    ScrollScreen(driver, epochs=2)\n",
    "    # get infor by search and choose the first one as PLAYLIST\n",
    "    playlist_list_url = getElements(driver, By.CSS_SELECTOR, '.sc-link-primary.soundTitle__title.sc-link-dark.sc-text-h4')\n",
    "    playlist_dict = addValue(playlist_dict, 'Name', playlist_list_url[iter].text)\n",
    "    getRequest(driver, playlist_list_url[iter].get_attribute('href'))\n",
    "    playlist_dict = Get_playlist_infor(driver, playlist_dict)\n",
    "    \n",
    "    # get random track from playlist for get specific infor TRACK\n",
    "    track_list_url = getElements(driver, By.CLASS_NAME, 'trackItem__trackTitle')\n",
    "    iter = random.randint(0, len(track_list_url)-1)\n",
    "    track_dict = addValue(track_dict, 'Name', track_list_url[iter].text)\n",
    "    getRequest(driver, track_list_url[iter].get_attribute('href'))\n",
    "    track_dict = Get_track_infor(driver, track_dict)\n",
    "\n",
    "    # get directly to the profile of current user\n",
    "    user_list_url = getElements(driver, By.CLASS_NAME,'sc-link-secondary')\n",
    "    user_dict = addValue(user_dict, 'Name', user_list_url[0].text)\n",
    "    getRequest(driver, user_list_url[0].get_attribute('href'))\n",
    "    user_dict = Get_user_infor(driver, user_dict)\n",
    "    return [playlist_dict, track_dict, user_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "df_playlist = pd.DataFrame(columns=['Name', 'Singer', 'Likes', 'Reposts', 'Release', 'Total_tracks'])\n",
    "df_track = pd.DataFrame(columns=['Name', 'Realease', 'Plays', 'Likes', 'Reposts'])\n",
    "df_user = pd.DataFrame(columns=['Name', 'Followers', 'Following', 'Tracks', 'Last_action', 'Last_track_played'])\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "data = []\n",
    "# run throw and search all the alphabet then choose 1 in them to check (24 alphabets -> 24 rows currently), loop 1 more loop for 40 cases of each alphabet (later)\n",
    "for char in alphabet:\n",
    "    url = target_web_link + '/search/sets?q=' + char\n",
    "    if (OpenWebBrowser(driver, url, id_coockie_trust=\"onetrust-accept-btn-handler\")):\n",
    "        data.append(Get_one_row_information(driver))\n",
    "    # test case on 1 alphabet first\n",
    "    break\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Name': 'Acid Jazz',\n",
       "   'Singer': 'TMN Playlisted',\n",
       "   'Likes': '388K',\n",
       "   'Reposts': '35.8K',\n",
       "   'Release': '6 years ago',\n",
       "   'Total_tracks': 50},\n",
       "  {'Name': '119',\n",
       "   'Release': '6 years ago',\n",
       "   'Plays': '5,045,518 plays',\n",
       "   'Likes': '34.6K',\n",
       "   'Reposts': '1,220'},\n",
       "  {'Name': 'TJCK',\n",
       "   'Followers': '898',\n",
       "   'Following': '30',\n",
       "   'Tracks': '4',\n",
       "   'Last_action': 'Reposted 3 months ago',\n",
       "   'Last_track_played': '94 plays'}]]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5c2883260794db105007a0ae85b8c56c71dc8b228bd32e0c1c65d05d5cfc592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
